{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "31266777-17bb-4c5b-b9cd-c180053cae58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status code: 200 (Success)\n",
      "robots.txt Content:\n",
      "User-agent: *\n",
      "Disallow: /\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def check_robots_txt(url):\n",
    "\n",
    "    robots_url = f\"{url}/robots.txt\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(robots_url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            print(f\"Status code: {response.status_code} (Success)\")\n",
    "            print(\"robots.txt Content:\")\n",
    "            print(response.text)\n",
    "        else:\n",
    "            print(f\"Status Code: {response.status_code} (No robots.txt found)\")\n",
    "\n",
    "    except Exception as e :\n",
    "        print(f\"Error occurred: {e}\")\n",
    "\n",
    "check_robots_txt(\"http://lecture.pul.kr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "54df3289-6095-4eda-8f7e-6df8722b4341",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import time\n",
    "\n",
    "def download_image(url, filename):\n",
    "     response = requests.get(url)\n",
    "    # if response.status_code == 200:\n",
    "     with open(filename,'wb') as f:\n",
    "        f.write(response.content)\n",
    "         \n",
    "url ='http://10.0.66.99/ex4.html'\n",
    "response = requests.get(url)\n",
    "soup = BeautifulSoup(response.text, 'html.parser')\n",
    "\n",
    "pdfs = soup.select('div.pdf_doc > .download-link')\n",
    "\n",
    "for fn, pdf in enumerate(pdfs,1):\n",
    "\n",
    "    src = pdf['href']\n",
    "    download_pdf(\"http://10.0.66.99/ex4.html\"+src, f'pdf_{fn:02}.pdf')\n",
    "    time.sleep(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "7c678a25-24d0-4334-9243-6db93b73c537",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['https://example.com/home', 'https://example.com/about', 'https://example.com/contact', 'https://example.com/article/1', 'https://example.com/article/2', 'https://example.com/article/1', 'https://example.com/article/3']\n",
      "['https://example.com/about', 'https://example.com/article/3', 'https://example.com/article/1', 'https://example.com/home', 'https://example.com/article/2', 'https://example.com/contact']\n"
     ]
    }
   ],
   "source": [
    "# 네이게이션 링크 추출 \n",
    "# 글 링크 추출\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html='''\n",
    "<nav class=\"navigation\">\n",
    "    <ul class=\"menu\">\n",
    "        <li><a href=\"https://example.com/home\" class=\"nav-link\">홈</a></li>\n",
    "        <li><a href=\"https://example.com/about\" class=\"nav-link\">소개</a></li>\n",
    "        <li><a href=\"https://example.com/contact\" class=\"nav-link\">연락처</a></li>\n",
    "    </ul>\n",
    "</nav>\n",
    "<div class=\"content\">\n",
    "    <a href=\"https://example.com/article/1\" class=\"article-link\">첫 번째 글</a>\n",
    "    <a href=\"https://example.com/article/2\" class=\"article-link\">두 번째 글</a>\n",
    "</div>\n",
    "<div class=\"footer\">\n",
    "    <a href=\"https://example.com/article/1\" class=\"article-link\">인기 많은 글</a>\n",
    "    <a href=\"https://example.com/article/3\" class=\"article-link\">조회수 많은 글</a>\n",
    "</div>\n",
    "'''\n",
    "soup = BeautifulSoup(html,\"html.parser\")\n",
    "\n",
    "mylink = []\n",
    "\n",
    "nav_links = soup.select('.nav-link')\n",
    "\n",
    "for link in nav_links:\n",
    "    mylink.append(link['href'])\n",
    "\n",
    "\n",
    "article_links = soup.select('.article-link')\n",
    "\n",
    "for link in article_links:\n",
    "    mylink.append(link['href'])\n",
    "print(mylink)\n",
    "mylink = list(set(mylink))\n",
    "print(mylink)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "id": "d0e83c38-4061-4275-a766-9f2f64a688a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "html_doc='''\n",
    "<table class=\"data-table\">\n",
    "    <thead>\n",
    "        <tr>\n",
    "            <th>순위</th>\n",
    "            <th>이름</th>\n",
    "            <th>점수</th>\n",
    "            <th>등급</th>\n",
    "        </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "        <tr class=\"student-row\">\n",
    "            <td class=\"rank\">1</td>\n",
    "            <td class=\"name\">김철수</td>\n",
    "            <td class=\"score\">95</td>\n",
    "            <td class=\"grade\">A+</td>\n",
    "        </tr>\n",
    "        <tr class=\"student-row\">\n",
    "            <td class=\"rank\">2</td>\n",
    "            <td class=\"name\">이영희</td>\n",
    "            <td class=\"score\">88</td>\n",
    "            <td class=\"grade\">B+</td>\n",
    "        </tr>\n",
    "    </tbody>\n",
    "</table>\n",
    "'''\n",
    "soup = BeautifulSoup(html_doc,\"html.parser\")\n",
    "headers = [th.text for th in soup.select ('thead th')]\n",
    "data = []\n",
    "rows = soup.select('tbody tr.student-row')\n",
    "for row in rows:\n",
    "    \n",
    "    raw_data = [\n",
    "        row.select_one('.rank').text,\n",
    "        row.select_one('.name').text,\n",
    "        row.select_one('.score').text,\n",
    "        row.select_one('.grade').text\n",
    "    ]\n",
    "\n",
    "    # raw_data = [\n",
    "    #     row.select_one('td')[0].text,\n",
    "    #     row.select_one('td')[1].text,\n",
    "    #     row.select_one('td')[2].text,\n",
    "    #     row.select_one('td')[3].text\n",
    "    # ]\n",
    "     #raw_data = [td.text for td in row.select('td')]\n",
    "    data.append(raw_data)\n",
    "\n",
    "df = pd.DataFrame(data, columns=headers)\n",
    "df.to_csv('student_scores.csv',index =False, encoding='utf-8')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "6cd25540-d354-48fd-8474-1d8407b344a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "username: test_user\n",
      "email: test@example.com\n",
      "interests: tech\n",
      "subscribe: True\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "import pandas as pd\n",
    "html_doc='''\n",
    "<form class=\"login-form\">\n",
    "    <div class=\"form-group\">\n",
    "        <label for=\"username\">사용자명:</label>\n",
    "        <input type=\"text\" id=\"username\" name=\"username\" value=\"test_user\" class=\"form-control\">\n",
    "    </div>\n",
    "    <div class=\"form-group\">\n",
    "        <label for=\"email\">이메일:</label>\n",
    "        <input type=\"email\" id=\"email\" name=\"email\" value=\"test@example.com\" class=\"form-control\">\n",
    "    </div>\n",
    "    <div class=\"form-group\">\n",
    "        <label>관심사:</label>\n",
    "        <select name=\"interests\" class=\"form-control\">\n",
    "            <option value=\"tech\" selected>기술</option>\n",
    "            <option value=\"science\">과학</option>\n",
    "            <option value=\"art\">예술</option>\n",
    "        </select>\n",
    "    </div>\n",
    "    <div class=\"form-group\">\n",
    "        <label>구독 여부:</label>\n",
    "        <input type=\"checkbox\" name=\"subscribe\" checked class=\"form-check\">\n",
    "    </div>\n",
    "</form>\n",
    "'''\n",
    "\n",
    "soup = BeautifulSoup(html_doc,\"html.parser\")\n",
    "form_data = {}\n",
    "# 입력필드 (택스트, 이메일)\n",
    "inputs = soup.select(\"input[type='text'],input[type = 'email']\")\n",
    "for input in inputs:\n",
    "    #print(input)\n",
    "    #form_data[input['name']] = input['value']\n",
    "    form_data[input['name']] = input.get('value','') # 안전한 값 가져오기 (기본값 지정)\n",
    "\n",
    "# 선택된 옵션\n",
    "select_opt = soup.select_one(\"select option[selected]\") # 선택된 항목만\n",
    "if  select_opt:\n",
    "    select_ele = select_opt.find_parent('select') # 부모 접근\n",
    "    form_data[select_ele['name']] = select_opt['value']\n",
    "\n",
    "# 체크박스\n",
    "checkbox = soup.select_one(\"input[type='checkbox']\")\n",
    "if checkbox:\n",
    "    form_data[checkbox['name']] = checkbox.has_attr('checked') # 속성 존재 여부\n",
    "                \n",
    "form_data\n",
    "\n",
    "# form_data\n",
    "\n",
    "for k,v in form_data.items():\n",
    "    print(f\"#{k}: {v}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "54aa46ef-a1de-4b8d-9c64-236df82b49cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'id': '1',\n",
       "  'src': 'image1.jpg',\n",
       "  'alt': '첫 번째 이미지',\n",
       "  'title': '아름다운 풍경',\n",
       "  'photographer': '촬영: 김작가'},\n",
       " {'id': '2',\n",
       "  'src': 'image2.jpg',\n",
       "  'alt': '두 번째 이미지',\n",
       "  'title': '도시의 밤',\n",
       "  'photographer': '촬영: 이작가'}]"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "html_doc='''\n",
    "<div class=\"gallery\">\n",
    "    <div class=\"image-container\">\n",
    "        <img src=\"image1.jpg\" alt=\"첫 번째 이미지\" class=\"gallery-image\" data-id=\"1\">\n",
    "        <div class=\"image-info\">\n",
    "            <span class=\"title\">아름다운 풍경</span>\n",
    "            <span class=\"photographer\">촬영: 김작가</span>\n",
    "        </div>\n",
    "    </div>\n",
    "    <div class=\"image-container\">\n",
    "        <img src=\"image2.jpg\" alt=\"두 번째 이미지\" class=\"gallery-image\" data-id=\"2\">\n",
    "        <div class=\"image-info\">\n",
    "            <span class=\"title\">도시의 밤</span>\n",
    "            <span class=\"photographer\">촬영: 이작가</span>\n",
    "        </div>\n",
    "    </div>\n",
    "</div>\n",
    "'''\n",
    "soup = BeautifulSoup(html_doc,\"html.parser\")\n",
    "images = []\n",
    "for container in soup.select('.image-container'):\n",
    "    img = container.select_one('img')\n",
    "    info = container.select_one('.image-info')\n",
    "    \n",
    "    image_data = {\n",
    "        'id' : img['data-id'],\n",
    "        'src' : img['src'],\n",
    "        'alt' : img['alt'],\n",
    "        'title' : info.select_one('.title').text,\n",
    "        'photographer': info.select_one('.photographer').text,\n",
    "    \n",
    "}\n",
    "\n",
    "    images.append(image_data)\n",
    "images\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0c8f2e8-ba39-4994-b2c0-91f9cd7dd60e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
